{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mNdzSD_7Xj4M"},"outputs":[],"source":["# Data Augmentation and L2 Regularization with Dropout and Early stopping"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295,"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","headers":[["content-type","application/javascript"]],"ok":true,"status":200,"status_text":""}}},"executionInfo":{"elapsed":28330,"status":"ok","timestamp":1644350091089,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"},"user_tz":300},"id":"oi82yu2HYGPG","outputId":"1c94ec0d-51ee-4bed-a147-c5d71ce91962"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"]},{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-92558987-d7e5-4e45-8e71-b95d239fcd4e\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-92558987-d7e5-4e45-8e71-b95d239fcd4e\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n"]},{"output_type":"execute_result","data":{"text/plain":["{'kaggle.json': b'{\"username\":\"isaac000o\",\"key\":\"2c1a236c98c03c0ce703259671092452\"}'}"]},"metadata":{},"execution_count":1}],"source":["!pip install kaggle\n","from google.colab import files\n","files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1315,"status":"ok","timestamp":1644214475293,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"},"user_tz":300},"id":"Url0uiPvYOjP","outputId":"a4386b6a-10c3-4fed-d734-202bfd3c02ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading alzheimermridataset.zip to /content\n"," 79% 49.0M/61.8M [00:00<00:00, 226MB/s]\n","100% 61.8M/61.8M [00:00<00:00, 244MB/s]\n"]}],"source":["!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","!kaggle datasets download -d legendahmed/alzheimermridataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1643,"status":"ok","timestamp":1644214479307,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"},"user_tz":300},"id":"bu-b6eBAYUqj","outputId":"5b556e2f-9eb5-4bd6-d914-8d164cba01b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting of the file ...\n","Done\n"]}],"source":["from zipfile import ZipFile\n","filename = \"alzheimermridataset.zip\"\n","\n","with ZipFile(filename,'r') as zip:\n","  print(\"Extracting of the file ...\")\n","  zip.extractall()\n","  print(\"Done\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rwoeyw4OYgLA"},"outputs":[],"source":["#libraries \n","from imutils import paths\n","import cv2\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Dropout, Flatten, Dense, MaxPool2D\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.optimizers import Adam, SGD\n","from keras.callbacks import EarlyStopping\n","from keras.callbacks import ModelCheckpoint\n","from matplotlib import pyplot\n","import tensorflow as tf\n","from keras.models import load_model\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4365,"status":"ok","timestamp":1644214490168,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"},"user_tz":300},"id":"qm_mTxfeY923","outputId":"f6149fc2-d2c7-4084-b5e9-bac7acc7b098"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Images: 5121\n","Number of Images: 1279\n"]}],"source":["Training_images_paths = list(paths.list_images(\"/content/Alzheimer_s Dataset/train\"))\n","Training_labels = []\n","Training_images = []\n","\n","i = 0 \n","while i < len(Training_images_paths):\n","  Training_labels.append(Training_images_paths[i].split(\"/\")[4])\n","  image = cv2.imread(Training_images_paths[i])\n","  image = cv2.resize(image,(256,256))\n","  Training_images.append(image)\n","  i = i + 1\n","\n","\n","\n","print(\"Number of Images:\",len(Training_labels))\n","\n","\n","\n","Testing_images_paths = list(paths.list_images(\"/content/Alzheimer_s Dataset/test\"))\n","Testing_labels = []\n","Testing_images = []\n","\n","i = 0 \n","while i < len(Testing_images_paths):\n","  Testing_labels.append(Testing_images_paths[i].split(\"/\")[4])\n","  image = cv2.imread(Testing_images_paths[i])\n","  image = cv2.resize(image,(256,256))\n","  Testing_images.append(image)\n","  i = i + 1\n","\n","\n","\n","print(\"Number of Images:\",len(Testing_labels))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"33XjjPr6ZD-t"},"outputs":[],"source":["data_generator = ImageDataGenerator(horizontal_flip=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YoCdR-qTZKLb"},"outputs":[],"source":["Training_images_np = np.array(Training_images) \n","Training_labels_np = np.array(Training_labels)\n","\n","Testing_images_np = np.array(Testing_images) \n","Testing_labels_np = np.array(Testing_labels)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10853,"status":"ok","timestamp":1644214503072,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"},"user_tz":300},"id":"LR_WNMPUZTW6","outputId":"3dbee2db-900b-43f1-e8f8-d7a545fc0bd4"},"outputs":[{"output_type":"stream","name":"stdout","text":["17920\n"]}],"source":["aug_traning_images_VeryMildDemented = []\n","aug_traning_labels_VeryMildDemented = []\n","v = 0 \n","while v < 1792:\n","  traning_image = Training_images_np[v]\n","  traning_image = traning_image.reshape((1,)+traning_image.shape)\n","  it = data_generator.flow(traning_image,batch_size=1,shuffle=True)\n","\n","  for i in range(10):\n","    batch = it.next()\n","    aug_traning_image = batch[0].astype('uint8') \n","    aug_traning_images_VeryMildDemented.append(aug_traning_image)\n","    aug_traning_labels_VeryMildDemented.append(Training_labels[v])\n","  v = v+1\n","\n","print(len(aug_traning_labels_VeryMildDemented))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12287,"status":"ok","timestamp":1644214515352,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"},"user_tz":300},"id":"tb27t6pMZV5u","outputId":"8a2abb58-b6a9-4f0e-dc1b-739769d0761e"},"outputs":[{"output_type":"stream","name":"stdout","text":["20800\n"]}],"source":["aug_traning_images_ModerateDemented = []\n","aug_traning_labels_ModerateDemented = []\n","\n","v = 1792 \n","while v < 1844:\n","  traning_image = Training_images_np[v]\n","  traning_image = traning_image.reshape((1,)+traning_image.shape)\n","  it = data_generator.flow(traning_image,batch_size=1,shuffle=True)\n","\n","  for i in range(400):\n","    batch = it.next()\n","    aug_traning_image = batch[0].astype('uint8') \n","    aug_traning_images_ModerateDemented.append(aug_traning_image)\n","    aug_traning_labels_ModerateDemented.append(Training_labels[v])\n","  v = v+1\n","print(len(aug_traning_labels_ModerateDemented))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9828,"status":"ok","timestamp":1644214525177,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"},"user_tz":300},"id":"tMOjibP3ZYZS","outputId":"9505fdd0-7fb7-487c-b365-a408cbf24623"},"outputs":[{"output_type":"stream","name":"stdout","text":["15360\n"]}],"source":["aug_traning_images_NonDemented = []\n","aug_traning_labels_NonDemented = []\n","\n","v = 1844 \n","while v < 4404:\n","  traning_image = Training_images_np[v]\n","  traning_image = traning_image.reshape((1,)+traning_image.shape)\n","  it = data_generator.flow(traning_image,batch_size=1,shuffle=True)\n","\n","  for i in range(6):\n","    batch = it.next()\n","    aug_traning_image = batch[0].astype('uint8') \n","    aug_traning_images_NonDemented.append(aug_traning_image)\n","    aug_traning_labels_NonDemented.append(Training_labels[v])\n","  v = v+1\n","\n","\n","\n","print(len(aug_traning_labels_NonDemented))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10882,"status":"ok","timestamp":1644214536054,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"},"user_tz":300},"id":"gU7pkLiDZa_m","outputId":"b300c694-51a6-41c8-e0d1-1aacbe574e21"},"outputs":[{"output_type":"stream","name":"stdout","text":["17925\n"]}],"source":["aug_traning_images_MildDemented = []\n","aug_traning_labels_MildDemented = []\n","\n","v = 4404 \n","while v < len(Training_labels):\n","  traning_image = Training_images_np[v]\n","  traning_image = traning_image.reshape((1,)+traning_image.shape)\n","  it = data_generator.flow(traning_image,batch_size=1,shuffle=True)\n","\n","  for i in range(25):\n","    batch = it.next()\n","    aug_traning_image = batch[0].astype('uint8') \n","    aug_traning_images_MildDemented.append(aug_traning_image)\n","    aug_traning_labels_MildDemented.append(Training_labels[v])\n","  v = v+1\n","\n","\n","print(len(aug_traning_labels_MildDemented))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1644214536054,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"},"user_tz":300},"id":"6_dO25cFZdR3","outputId":"57d336dc-4027-43b2-e3a7-f2cff4914bfe"},"outputs":[{"output_type":"stream","name":"stdout","text":["77126\n","77126\n"]}],"source":["aug_traning_images = aug_traning_images_MildDemented + aug_traning_images_NonDemented + aug_traning_images_ModerateDemented + aug_traning_images_VeryMildDemented+Training_images\n","aug_traning_labels = aug_traning_labels_MildDemented + aug_traning_labels_NonDemented + aug_traning_labels_ModerateDemented + aug_traning_labels_VeryMildDemented+Training_labels\n","\n","print(len(aug_traning_images))\n","print(len(aug_traning_labels))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2574,"status":"ok","timestamp":1644214538614,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"},"user_tz":300},"id":"Lg7jzPXjZfLh","outputId":"5902cfec-a050-446a-de41-8ba40e98b348"},"outputs":[{"output_type":"stream","name":"stdout","text":["4032\n"]}],"source":["aug_testing_images_VeryMildDemented = []\n","aug_testing_labels_VeryMildDemented = []\n","x = 0 \n","while x < 448:\n","  testing_image = Testing_images_np[x]\n","  testing_image = testing_image.reshape((1,)+testing_image.shape)\n","  it = data_generator.flow(testing_image,batch_size=1,shuffle=True)\n","\n","  for i in range(9):\n","    batch = it.next()\n","    aug_testing_image = batch[0].astype('uint8') \n","    aug_testing_images_VeryMildDemented.append(aug_testing_image)\n","    aug_testing_labels_VeryMildDemented.append(Testing_labels[x])\n","  x = x+1\n","\n","print(len(aug_testing_labels_VeryMildDemented))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3077,"status":"ok","timestamp":1644214541671,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"},"user_tz":300},"id":"2A5x2XOnZhMP","outputId":"9ee1b52e-ca0a-4ef0-955b-43bf99d7e8b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["4800\n"]}],"source":["aug_testing_images_ModerateDemented = []\n","aug_testing_labels_ModerateDemented = []\n","x = 448 \n","while x < 460:\n","  testing_image = Testing_images_np[x]\n","  testing_image = testing_image.reshape((1,)+testing_image.shape)\n","  it = data_generator.flow(testing_image,batch_size=1,shuffle=True)\n","\n","  for i in range(400):\n","    batch = it.next()\n","    aug_testing_image = batch[0].astype('uint8') \n","    aug_testing_images_ModerateDemented.append(aug_testing_image)\n","    aug_testing_labels_ModerateDemented.append(Testing_labels[x])\n","  x = x+1\n","\n","print(len(aug_testing_labels_ModerateDemented))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2948,"status":"ok","timestamp":1644214544614,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"},"user_tz":300},"id":"YUbxr7gCZjIY","outputId":"aa598064-b96b-4111-fa49-67e1fcb3a5d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["5120\n"]}],"source":["aug_testing_images_NonDemented = []\n","aug_testing_labels_NonDemented = []\n","x = 460 \n","while x < 1100:\n","  testing_image = Testing_images_np[x]\n","  testing_image = testing_image.reshape((1,)+testing_image.shape)\n","  it = data_generator.flow(testing_image,batch_size=1,shuffle=True)\n","\n","  for i in range(8):\n","    batch = it.next()\n","    aug_testing_image = batch[0].astype('uint8') \n","    aug_testing_images_NonDemented.append(aug_testing_image)\n","    aug_testing_labels_NonDemented.append(Testing_labels[x])\n","  x = x+1\n","\n","print(len(aug_testing_labels_NonDemented))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3306,"status":"ok","timestamp":1644214547916,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"},"user_tz":300},"id":"rmWpMw99ZlPm","outputId":"02445e55-68dc-4ebd-887f-87e438aaedb6"},"outputs":[{"output_type":"stream","name":"stdout","text":["5370\n"]}],"source":["aug_testing_images_MildDemented = []\n","aug_testing_labels_MildDemented = []\n","x = 1100 \n","\n","while x < len(Testing_labels):\n","  testing_image = Testing_images_np[x]\n","  testing_image = testing_image.reshape((1,)+testing_image.shape)\n","  it = data_generator.flow(testing_image,batch_size=1,shuffle=True)\n","  #130\n","  for i in range(30):\n","    batch = it.next()\n","    aug_testing_image = batch[0].astype('uint8') \n","    aug_testing_images_MildDemented.append(aug_testing_image)\n","    aug_testing_labels_MildDemented.append(Testing_labels[x])\n","  x = x+1\n","\n","print(len(aug_testing_labels_MildDemented))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1644214547916,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"},"user_tz":300},"id":"VjUpmIpzZnIo","outputId":"ba556505-c23a-4007-ecd2-2d7f7b402734"},"outputs":[{"output_type":"stream","name":"stdout","text":["20601\n","20601\n"]}],"source":["aug_testing_images = aug_testing_images_MildDemented + aug_testing_images_NonDemented + aug_testing_images_ModerateDemented + aug_testing_images_VeryMildDemented + Testing_images\n","aug_testing_labels = aug_testing_labels_MildDemented + aug_testing_labels_NonDemented + aug_testing_labels_ModerateDemented + aug_testing_labels_VeryMildDemented + Testing_labels\n","\n","print(len(aug_testing_images))\n","print(len(aug_testing_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14546,"status":"ok","timestamp":1644214562459,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"},"user_tz":300},"id":"Yef8MKtNZpP8","outputId":"9801b045-c690-423f-c882-215f16729e47"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'list'>\n","<class 'numpy.ndarray'>\n","(77126,)\n","(20601,)\n","(77126, 128, 128, 1)\n","(77126, 4)\n","(20601, 128, 128, 1)\n","(20601, 4)\n"]}],"source":["i = 0 \n","while i <len(aug_traning_images):\n","  image = aug_traning_images[i]\n","  image = cv2.resize(image,(128,128))\n","  image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n","  aug_traning_images[i] = image\n","  i = i + 1\n","\n","\n","n = 0 \n","while n < len(aug_testing_images):\n","  image = aug_testing_images[n]\n","  image = cv2.resize(image,(128,128))\n","  image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n","  aug_testing_images[n] = image\n","  n = n + 1\n","\n","print(type(aug_traning_images))\n","aug_traning_images = np.array(aug_traning_images)\n","aug_testing_images = np.array(aug_testing_images)\n","print(type(aug_traning_images))\n","\n","\n","aug_traning_images = aug_traning_images/255.00\n","aug_testing_images = aug_testing_images/255.00\n","\n","label_encoder = LabelEncoder()\n","\n","aug_traning_labels = label_encoder.fit_transform(aug_traning_labels)\n","print(aug_traning_labels.shape)\n","\n","label_encoder = LabelEncoder()\n","aug_testing_labels = label_encoder.fit_transform(aug_testing_labels)\n","print(aug_testing_labels.shape)\n","\n","aug_traning_labels = to_categorical(aug_traning_labels)\n","aug_testing_labels = to_categorical(aug_testing_labels)\n","\n","aug_traning_images = np.expand_dims(aug_traning_images, axis=-1)\n","aug_testing_images = np.expand_dims(aug_testing_images, axis=-1)\n","\n","\n","print(aug_traning_images.shape)\n","print(aug_traning_labels.shape)\n","print(aug_testing_images.shape)\n","print(aug_testing_labels.shape)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"O0ge_tfca5Ro","executionInfo":{"status":"ok","timestamp":1644370551034,"user_tz":300,"elapsed":363,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"}}},"outputs":[],"source":["def Alzheimer_Data_Augmentation_L2_Dropout_Earlystopping(input_shape=(128, 128, 1)):\n","    regularizer = tf.keras.regularizers.l2(0.001)\n","    model = Sequential()\n","    model.add(Input(shape=input_shape))\n","    model.add(Conv2D(128, (5, 5), padding='same', strides=(1, 1), name='conv1', activation='sigmoid', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((9, 9), strides=(3, 3)))\n","    model.add(Conv2D(64, (5, 5), padding='same', strides=(1, 1), name='conv2', activation='sigmoid', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((7, 7), strides=(3, 3)))\n","    model.add(Conv2D(32, (3, 3), padding='same', strides=(1, 1), name='conv3', activation='sigmoid', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((5, 5), strides=(2, 2)))\n"," #   model.add(Conv2D(32, (3, 3), padding='same', strides=(1, 1), name='conv4', activation='relu', kernel_regularizer=regularizer))\n"," #   model.add(MaxPool2D((3, 3), strides=(2, 2)))    \n","    \n","    model.add(Flatten())\n","    model.add(Dropout(0.5))\n","    model.add(Dense(64, activation='sigmoid'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(4, activation='sigmoid'))\n","    optimizer = Adam(3.15e-5)\n","    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":338},"executionInfo":{"elapsed":515,"status":"error","timestamp":1644370554232,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"},"user_tz":300},"id":"Ofa3mN46bQ9E","outputId":"7f5e4878-f724-436c-b82e-09e9fcd6f464"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-18518ed97d37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mAlzheimer_Data_Augmentation_L2_Dropout_Earlystopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-5be4f1a5bd62>\u001b[0m in \u001b[0;36mAlzheimer_Data_Augmentation_L2_Dropout_Earlystopping\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mAlzheimer_Data_Augmentation_L2_Dropout_Earlystopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mregularizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"]}],"source":["model= Alzheimer_Data_Augmentation_L2_Dropout_Earlystopping(input_shape=(128, 128, 1))\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KAGV-_2xblvP"},"outputs":[],"source":["#Setting up Early Stopping\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n","mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"ngUMRPLsbumm","outputId":"b0bc3acb-5eec-405a-e75b-121489ad859f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/200\n","603/603 [==============================] - ETA: 0s - loss: 1.2663 - accuracy: 0.5182\n","Epoch 00001: val_accuracy improved from -inf to 0.52968, saving model to best_model.h5\n","603/603 [==============================] - 58s 96ms/step - loss: 1.2663 - accuracy: 0.5182 - val_loss: 1.1628 - val_accuracy: 0.5297\n","Epoch 2/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.1341 - accuracy: 0.5602\n","Epoch 00002: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 1.1341 - accuracy: 0.5601 - val_loss: 1.1227 - val_accuracy: 0.5297\n","Epoch 3/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0904 - accuracy: 0.5761\n","Epoch 00003: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 1.0904 - accuracy: 0.5761 - val_loss: 1.0975 - val_accuracy: 0.5297\n","Epoch 4/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0640 - accuracy: 0.5831\n","Epoch 00004: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 1.0638 - accuracy: 0.5833 - val_loss: 1.0858 - val_accuracy: 0.5297\n","Epoch 5/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0482 - accuracy: 0.5865\n","Epoch 00005: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 1.0482 - accuracy: 0.5865 - val_loss: 1.0755 - val_accuracy: 0.5297\n","Epoch 6/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0392 - accuracy: 0.5880\n","Epoch 00006: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 1.0392 - accuracy: 0.5879 - val_loss: 1.0706 - val_accuracy: 0.5297\n","Epoch 7/200\n","603/603 [==============================] - ETA: 0s - loss: 1.0300 - accuracy: 0.5891\n","Epoch 00007: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 1.0300 - accuracy: 0.5891 - val_loss: 1.0658 - val_accuracy: 0.5297\n","Epoch 8/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0253 - accuracy: 0.5900\n","Epoch 00008: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 1.0253 - accuracy: 0.5900 - val_loss: 1.0624 - val_accuracy: 0.5297\n","Epoch 9/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0181 - accuracy: 0.5904\n","Epoch 00009: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 1.0181 - accuracy: 0.5904 - val_loss: 1.0577 - val_accuracy: 0.5297\n","Epoch 10/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0116 - accuracy: 0.5905\n","Epoch 00010: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 1.0116 - accuracy: 0.5905 - val_loss: 1.0544 - val_accuracy: 0.5297\n","Epoch 11/200\n","603/603 [==============================] - ETA: 0s - loss: 1.0081 - accuracy: 0.5907\n","Epoch 00011: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 1.0081 - accuracy: 0.5907 - val_loss: 1.0526 - val_accuracy: 0.5297\n","Epoch 12/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0035 - accuracy: 0.5907\n","Epoch 00012: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 1.0035 - accuracy: 0.5908 - val_loss: 1.0519 - val_accuracy: 0.5297\n","Epoch 13/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0014 - accuracy: 0.5909\n","Epoch 00013: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 1.0014 - accuracy: 0.5909 - val_loss: 1.0489 - val_accuracy: 0.5297\n","Epoch 14/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9987 - accuracy: 0.5909\n","Epoch 00014: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9987 - accuracy: 0.5909 - val_loss: 1.0470 - val_accuracy: 0.5297\n","Epoch 15/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9962 - accuracy: 0.5910\n","Epoch 00015: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9962 - accuracy: 0.5909 - val_loss: 1.0472 - val_accuracy: 0.5297\n","Epoch 16/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9944 - accuracy: 0.5909\n","Epoch 00016: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9943 - accuracy: 0.5909 - val_loss: 1.0470 - val_accuracy: 0.5297\n","Epoch 17/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9921 - accuracy: 0.5909\n","Epoch 00017: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9921 - accuracy: 0.5909 - val_loss: 1.0444 - val_accuracy: 0.5297\n","Epoch 18/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9903 - accuracy: 0.5909\n","Epoch 00018: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9903 - accuracy: 0.5909 - val_loss: 1.0434 - val_accuracy: 0.5297\n","Epoch 19/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9901 - accuracy: 0.5909\n","Epoch 00019: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 92ms/step - loss: 0.9901 - accuracy: 0.5909 - val_loss: 1.0450 - val_accuracy: 0.5297\n","Epoch 20/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9892 - accuracy: 0.5909\n","Epoch 00020: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 92ms/step - loss: 0.9892 - accuracy: 0.5909 - val_loss: 1.0436 - val_accuracy: 0.5297\n","Epoch 21/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9872 - accuracy: 0.5909\n","Epoch 00021: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9872 - accuracy: 0.5909 - val_loss: 1.0424 - val_accuracy: 0.5297\n","Epoch 22/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9868 - accuracy: 0.5910\n","Epoch 00022: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 92ms/step - loss: 0.9868 - accuracy: 0.5909 - val_loss: 1.0446 - val_accuracy: 0.5297\n","Epoch 23/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9870 - accuracy: 0.5910\n","Epoch 00023: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9870 - accuracy: 0.5909 - val_loss: 1.0408 - val_accuracy: 0.5297\n","Epoch 24/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9857 - accuracy: 0.5909\n","Epoch 00024: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9857 - accuracy: 0.5909 - val_loss: 1.0417 - val_accuracy: 0.5297\n","Epoch 25/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9840 - accuracy: 0.5909\n","Epoch 00025: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9840 - accuracy: 0.5909 - val_loss: 1.0428 - val_accuracy: 0.5297\n","Epoch 26/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9847 - accuracy: 0.5910\n","Epoch 00026: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9848 - accuracy: 0.5909 - val_loss: 1.0436 - val_accuracy: 0.5297\n","Epoch 27/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9856 - accuracy: 0.5908\n","Epoch 00027: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9855 - accuracy: 0.5909 - val_loss: 1.0447 - val_accuracy: 0.5297\n","Epoch 28/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9837 - accuracy: 0.5909\n","Epoch 00028: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9837 - accuracy: 0.5909 - val_loss: 1.0408 - val_accuracy: 0.5297\n","Epoch 29/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9833 - accuracy: 0.5909\n","Epoch 00029: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9834 - accuracy: 0.5909 - val_loss: 1.0422 - val_accuracy: 0.5297\n","Epoch 30/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9838 - accuracy: 0.5909\n","Epoch 00030: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9838 - accuracy: 0.5909 - val_loss: 1.0418 - val_accuracy: 0.5297\n","Epoch 31/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9826 - accuracy: 0.5909\n","Epoch 00031: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9826 - accuracy: 0.5909 - val_loss: 1.0421 - val_accuracy: 0.5297\n","Epoch 32/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9829 - accuracy: 0.5909\n","Epoch 00032: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9829 - accuracy: 0.5909 - val_loss: 1.0431 - val_accuracy: 0.5297\n","Epoch 33/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9827 - accuracy: 0.5909\n","Epoch 00033: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9826 - accuracy: 0.5909 - val_loss: 1.0407 - val_accuracy: 0.5297\n","Epoch 34/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9818 - accuracy: 0.5909\n","Epoch 00034: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9818 - accuracy: 0.5909 - val_loss: 1.0441 - val_accuracy: 0.5297\n","Epoch 35/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9822 - accuracy: 0.5910\n","Epoch 00035: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9822 - accuracy: 0.5909 - val_loss: 1.0400 - val_accuracy: 0.5297\n","Epoch 36/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9816 - accuracy: 0.5909\n","Epoch 00036: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9817 - accuracy: 0.5909 - val_loss: 1.0420 - val_accuracy: 0.5297\n","Epoch 37/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9819 - accuracy: 0.5909\n","Epoch 00037: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9819 - accuracy: 0.5909 - val_loss: 1.0405 - val_accuracy: 0.5297\n","Epoch 38/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9816 - accuracy: 0.5909\n","Epoch 00038: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9816 - accuracy: 0.5909 - val_loss: 1.0405 - val_accuracy: 0.5297\n","Epoch 39/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9816 - accuracy: 0.5910\n","Epoch 00039: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9817 - accuracy: 0.5909 - val_loss: 1.0399 - val_accuracy: 0.5297\n","Epoch 40/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9816 - accuracy: 0.5909\n","Epoch 00040: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9816 - accuracy: 0.5909 - val_loss: 1.0434 - val_accuracy: 0.5297\n","Epoch 41/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9816 - accuracy: 0.5910\n","Epoch 00041: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9817 - accuracy: 0.5909 - val_loss: 1.0418 - val_accuracy: 0.5297\n","Epoch 42/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9820 - accuracy: 0.5908\n","Epoch 00042: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9819 - accuracy: 0.5909 - val_loss: 1.0410 - val_accuracy: 0.5297\n","Epoch 43/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9809 - accuracy: 0.5909\n","Epoch 00043: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9808 - accuracy: 0.5909 - val_loss: 1.0432 - val_accuracy: 0.5297\n","Epoch 44/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9805 - accuracy: 0.5909\n","Epoch 00044: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9805 - accuracy: 0.5909 - val_loss: 1.0435 - val_accuracy: 0.5297\n","Epoch 45/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9812 - accuracy: 0.5909\n","Epoch 00045: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9813 - accuracy: 0.5909 - val_loss: 1.0434 - val_accuracy: 0.5297\n","Epoch 46/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9803 - accuracy: 0.5909\n","Epoch 00046: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9802 - accuracy: 0.5909 - val_loss: 1.0440 - val_accuracy: 0.5297\n","Epoch 47/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9809 - accuracy: 0.5909\n","Epoch 00047: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 92ms/step - loss: 0.9808 - accuracy: 0.5909 - val_loss: 1.0441 - val_accuracy: 0.5297\n","Epoch 48/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9804 - accuracy: 0.5910\n","Epoch 00048: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9805 - accuracy: 0.5909 - val_loss: 1.0438 - val_accuracy: 0.5297\n","Epoch 49/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9810 - accuracy: 0.5909\n","Epoch 00049: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9810 - accuracy: 0.5909 - val_loss: 1.0436 - val_accuracy: 0.5297\n","Epoch 50/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9798 - accuracy: 0.5909\n","Epoch 00050: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9798 - accuracy: 0.5909 - val_loss: 1.0431 - val_accuracy: 0.5297\n","Epoch 51/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9803 - accuracy: 0.5909\n","Epoch 00051: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9803 - accuracy: 0.5909 - val_loss: 1.0414 - val_accuracy: 0.5297\n","Epoch 52/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9800 - accuracy: 0.5909\n","Epoch 00052: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9800 - accuracy: 0.5909 - val_loss: 1.0432 - val_accuracy: 0.5297\n","Epoch 53/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9805 - accuracy: 0.5910\n","Epoch 00053: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9805 - accuracy: 0.5909 - val_loss: 1.0446 - val_accuracy: 0.5297\n","Epoch 54/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9799 - accuracy: 0.5909\n","Epoch 00054: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9798 - accuracy: 0.5909 - val_loss: 1.0386 - val_accuracy: 0.5297\n","Epoch 55/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9800 - accuracy: 0.5909\n","Epoch 00055: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9801 - accuracy: 0.5909 - val_loss: 1.0407 - val_accuracy: 0.5297\n","Epoch 56/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9797 - accuracy: 0.5909\n","Epoch 00056: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9797 - accuracy: 0.5909 - val_loss: 1.0413 - val_accuracy: 0.5297\n","Epoch 57/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9799 - accuracy: 0.5909\n","Epoch 00057: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9798 - accuracy: 0.5909 - val_loss: 1.0425 - val_accuracy: 0.5297\n","Epoch 58/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9796 - accuracy: 0.5909\n","Epoch 00058: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9796 - accuracy: 0.5909 - val_loss: 1.0436 - val_accuracy: 0.5297\n","Epoch 59/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9797 - accuracy: 0.5909\n","Epoch 00059: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9797 - accuracy: 0.5909 - val_loss: 1.0404 - val_accuracy: 0.5297\n","Epoch 60/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9797 - accuracy: 0.5909\n","Epoch 00060: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9797 - accuracy: 0.5909 - val_loss: 1.0435 - val_accuracy: 0.5297\n","Epoch 61/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9798 - accuracy: 0.5909\n","Epoch 00061: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9798 - accuracy: 0.5909 - val_loss: 1.0427 - val_accuracy: 0.5297\n","Epoch 62/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9792 - accuracy: 0.5909\n","Epoch 00062: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 92ms/step - loss: 0.9792 - accuracy: 0.5909 - val_loss: 1.0431 - val_accuracy: 0.5297\n","Epoch 63/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9790 - accuracy: 0.5909\n","Epoch 00063: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9790 - accuracy: 0.5909 - val_loss: 1.0425 - val_accuracy: 0.5297\n","Epoch 64/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9790 - accuracy: 0.5909\n","Epoch 00064: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9790 - accuracy: 0.5909 - val_loss: 1.0428 - val_accuracy: 0.5297\n","Epoch 65/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9794 - accuracy: 0.5911\n","Epoch 00065: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9796 - accuracy: 0.5909 - val_loss: 1.0411 - val_accuracy: 0.5297\n","Epoch 66/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9798 - accuracy: 0.5909\n","Epoch 00066: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9797 - accuracy: 0.5909 - val_loss: 1.0431 - val_accuracy: 0.5297\n","Epoch 67/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9792 - accuracy: 0.5909\n","Epoch 00067: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9792 - accuracy: 0.5909 - val_loss: 1.0419 - val_accuracy: 0.5297\n","Epoch 68/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9791 - accuracy: 0.5909\n","Epoch 00068: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9791 - accuracy: 0.5909 - val_loss: 1.0424 - val_accuracy: 0.5297\n","Epoch 69/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9791 - accuracy: 0.5909\n","Epoch 00069: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9791 - accuracy: 0.5909 - val_loss: 1.0427 - val_accuracy: 0.5297\n","Epoch 70/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9795 - accuracy: 0.5909\n","Epoch 00070: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 92ms/step - loss: 0.9794 - accuracy: 0.5909 - val_loss: 1.0392 - val_accuracy: 0.5297\n","Epoch 71/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9790 - accuracy: 0.5909\n","Epoch 00071: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9790 - accuracy: 0.5909 - val_loss: 1.0402 - val_accuracy: 0.5297\n","Epoch 72/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9793 - accuracy: 0.5910\n","Epoch 00072: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9793 - accuracy: 0.5909 - val_loss: 1.0434 - val_accuracy: 0.5297\n","Epoch 73/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9795 - accuracy: 0.5909\n","Epoch 00073: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9794 - accuracy: 0.5909 - val_loss: 1.0402 - val_accuracy: 0.5297\n","Epoch 74/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9794 - accuracy: 0.5909\n","Epoch 00074: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9794 - accuracy: 0.5909 - val_loss: 1.0423 - val_accuracy: 0.5297\n","Epoch 00074: early stopping\n","Train: 0.530, Test: 0.530\n"]}],"source":["hist_ = model.fit(aug_traning_images, aug_traning_labels, batch_size=128, epochs=200, validation_data=(aug_testing_images, aug_testing_labels), callbacks=[es, mc])\n","saved_model = load_model('best_model.h5')\n","# evaluate the model\n","_, train_acc = saved_model.evaluate(aug_testing_images, aug_testing_labels, verbose=0)\n","_, test_acc = saved_model.evaluate(aug_testing_images, aug_testing_labels, verbose=0)\n","print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tq0RnXo2_75h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644194873699,"user_tz":300,"elapsed":2911530,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"}},"outputId":"5c24f015-6ffb-4e1f-b3c4-17d80e17c69f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","603/603 [==============================] - ETA: 0s - loss: 1.6234 - accuracy: 0.3343\n","Epoch 00001: val_accuracy improved from -inf to 0.52968, saving model to best_model.h5\n","603/603 [==============================] - 65s 94ms/step - loss: 1.6234 - accuracy: 0.3343 - val_loss: 1.2204 - val_accuracy: 0.5297\n","Epoch 2/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.2632 - accuracy: 0.4929\n","Epoch 00002: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 1.2632 - accuracy: 0.4929 - val_loss: 1.1403 - val_accuracy: 0.5297\n","Epoch 3/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.1877 - accuracy: 0.5185\n","Epoch 00003: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 1.1877 - accuracy: 0.5185 - val_loss: 1.1081 - val_accuracy: 0.5297\n","Epoch 4/200\n","603/603 [==============================] - ETA: 0s - loss: 1.1440 - accuracy: 0.5248\n","Epoch 00004: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 1.1440 - accuracy: 0.5248 - val_loss: 1.0927 - val_accuracy: 0.5297\n","Epoch 5/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.1151 - accuracy: 0.5344\n","Epoch 00005: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 1.1151 - accuracy: 0.5345 - val_loss: 1.0807 - val_accuracy: 0.5297\n","Epoch 6/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0913 - accuracy: 0.5414\n","Epoch 00006: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 1.0914 - accuracy: 0.5413 - val_loss: 1.0726 - val_accuracy: 0.5297\n","Epoch 7/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0736 - accuracy: 0.5486\n","Epoch 00007: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 1.0735 - accuracy: 0.5487 - val_loss: 1.0670 - val_accuracy: 0.5297\n","Epoch 8/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0583 - accuracy: 0.5567\n","Epoch 00008: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 90ms/step - loss: 1.0583 - accuracy: 0.5566 - val_loss: 1.0628 - val_accuracy: 0.5297\n","Epoch 9/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0450 - accuracy: 0.5629\n","Epoch 00009: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 90ms/step - loss: 1.0450 - accuracy: 0.5629 - val_loss: 1.0590 - val_accuracy: 0.5297\n","Epoch 10/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0368 - accuracy: 0.5694\n","Epoch 00010: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 1.0368 - accuracy: 0.5694 - val_loss: 1.0560 - val_accuracy: 0.5297\n","Epoch 11/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0304 - accuracy: 0.5746\n","Epoch 00011: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 90ms/step - loss: 1.0305 - accuracy: 0.5746 - val_loss: 1.0547 - val_accuracy: 0.5297\n","Epoch 12/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0223 - accuracy: 0.5794\n","Epoch 00012: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 1.0223 - accuracy: 0.5795 - val_loss: 1.0521 - val_accuracy: 0.5297\n","Epoch 13/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0151 - accuracy: 0.5825\n","Epoch 00013: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 1.0151 - accuracy: 0.5825 - val_loss: 1.0506 - val_accuracy: 0.5297\n","Epoch 14/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0112 - accuracy: 0.5852\n","Epoch 00014: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 1.0113 - accuracy: 0.5851 - val_loss: 1.0502 - val_accuracy: 0.5297\n","Epoch 15/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0067 - accuracy: 0.5868\n","Epoch 00015: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 1.0066 - accuracy: 0.5869 - val_loss: 1.0485 - val_accuracy: 0.5297\n","Epoch 16/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0030 - accuracy: 0.5884\n","Epoch 00016: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 1.0030 - accuracy: 0.5883 - val_loss: 1.0476 - val_accuracy: 0.5297\n","Epoch 17/200\n","602/603 [============================>.] - ETA: 0s - loss: 1.0005 - accuracy: 0.5894\n","Epoch 00017: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 1.0006 - accuracy: 0.5894 - val_loss: 1.0468 - val_accuracy: 0.5297\n","Epoch 18/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9990 - accuracy: 0.5895\n","Epoch 00018: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 90ms/step - loss: 0.9990 - accuracy: 0.5895 - val_loss: 1.0458 - val_accuracy: 0.5297\n","Epoch 19/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9955 - accuracy: 0.5904\n","Epoch 00019: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9955 - accuracy: 0.5904 - val_loss: 1.0453 - val_accuracy: 0.5297\n","Epoch 20/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9944 - accuracy: 0.5906\n","Epoch 00020: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9945 - accuracy: 0.5905 - val_loss: 1.0448 - val_accuracy: 0.5297\n","Epoch 21/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9936 - accuracy: 0.5906\n","Epoch 00021: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9937 - accuracy: 0.5906 - val_loss: 1.0446 - val_accuracy: 0.5297\n","Epoch 22/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9905 - accuracy: 0.5908\n","Epoch 00022: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9905 - accuracy: 0.5908 - val_loss: 1.0448 - val_accuracy: 0.5297\n","Epoch 23/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9908 - accuracy: 0.5909\n","Epoch 00023: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9909 - accuracy: 0.5909 - val_loss: 1.0441 - val_accuracy: 0.5297\n","Epoch 24/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9898 - accuracy: 0.5909\n","Epoch 00024: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 55s 91ms/step - loss: 0.9897 - accuracy: 0.5909 - val_loss: 1.0442 - val_accuracy: 0.5297\n","Epoch 25/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9888 - accuracy: 0.5909\n","Epoch 00025: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9888 - accuracy: 0.5909 - val_loss: 1.0440 - val_accuracy: 0.5297\n","Epoch 26/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9871 - accuracy: 0.5910\n","Epoch 00026: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9872 - accuracy: 0.5909 - val_loss: 1.0438 - val_accuracy: 0.5297\n","Epoch 27/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9876 - accuracy: 0.5910\n","Epoch 00027: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9878 - accuracy: 0.5909 - val_loss: 1.0434 - val_accuracy: 0.5297\n","Epoch 28/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9871 - accuracy: 0.5909\n","Epoch 00028: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9871 - accuracy: 0.5909 - val_loss: 1.0431 - val_accuracy: 0.5297\n","Epoch 29/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9860 - accuracy: 0.5909\n","Epoch 00029: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9860 - accuracy: 0.5909 - val_loss: 1.0438 - val_accuracy: 0.5297\n","Epoch 30/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9861 - accuracy: 0.5909\n","Epoch 00030: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9861 - accuracy: 0.5909 - val_loss: 1.0434 - val_accuracy: 0.5297\n","Epoch 31/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9851 - accuracy: 0.5910\n","Epoch 00031: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9853 - accuracy: 0.5909 - val_loss: 1.0428 - val_accuracy: 0.5297\n","Epoch 32/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9849 - accuracy: 0.5910\n","Epoch 00032: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9850 - accuracy: 0.5909 - val_loss: 1.0426 - val_accuracy: 0.5297\n","Epoch 33/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9840 - accuracy: 0.5910\n","Epoch 00033: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 89ms/step - loss: 0.9841 - accuracy: 0.5909 - val_loss: 1.0419 - val_accuracy: 0.5297\n","Epoch 34/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9845 - accuracy: 0.5909\n","Epoch 00034: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 89ms/step - loss: 0.9845 - accuracy: 0.5909 - val_loss: 1.0429 - val_accuracy: 0.5297\n","Epoch 35/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9848 - accuracy: 0.5910\n","Epoch 00035: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9849 - accuracy: 0.5909 - val_loss: 1.0419 - val_accuracy: 0.5297\n","Epoch 36/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9845 - accuracy: 0.5910\n","Epoch 00036: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9845 - accuracy: 0.5909 - val_loss: 1.0432 - val_accuracy: 0.5297\n","Epoch 37/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9839 - accuracy: 0.5910\n","Epoch 00037: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9839 - accuracy: 0.5909 - val_loss: 1.0434 - val_accuracy: 0.5297\n","Epoch 38/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9833 - accuracy: 0.5909\n","Epoch 00038: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9832 - accuracy: 0.5909 - val_loss: 1.0428 - val_accuracy: 0.5297\n","Epoch 39/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9830 - accuracy: 0.5908\n","Epoch 00039: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9829 - accuracy: 0.5909 - val_loss: 1.0427 - val_accuracy: 0.5297\n","Epoch 40/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9828 - accuracy: 0.5909\n","Epoch 00040: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 89ms/step - loss: 0.9828 - accuracy: 0.5909 - val_loss: 1.0429 - val_accuracy: 0.5297\n","Epoch 41/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9829 - accuracy: 0.5909\n","Epoch 00041: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9828 - accuracy: 0.5909 - val_loss: 1.0426 - val_accuracy: 0.5297\n","Epoch 42/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9823 - accuracy: 0.5910\n","Epoch 00042: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 89ms/step - loss: 0.9824 - accuracy: 0.5909 - val_loss: 1.0426 - val_accuracy: 0.5297\n","Epoch 43/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9823 - accuracy: 0.5909\n","Epoch 00043: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9822 - accuracy: 0.5909 - val_loss: 1.0422 - val_accuracy: 0.5297\n","Epoch 44/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9828 - accuracy: 0.5908\n","Epoch 00044: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9827 - accuracy: 0.5909 - val_loss: 1.0427 - val_accuracy: 0.5297\n","Epoch 45/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9824 - accuracy: 0.5910\n","Epoch 00045: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9825 - accuracy: 0.5909 - val_loss: 1.0434 - val_accuracy: 0.5297\n","Epoch 46/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9818 - accuracy: 0.5909\n","Epoch 00046: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9818 - accuracy: 0.5909 - val_loss: 1.0424 - val_accuracy: 0.5297\n","Epoch 47/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9817 - accuracy: 0.5910\n","Epoch 00047: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9817 - accuracy: 0.5909 - val_loss: 1.0427 - val_accuracy: 0.5297\n","Epoch 48/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9812 - accuracy: 0.5909\n","Epoch 00048: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9812 - accuracy: 0.5909 - val_loss: 1.0422 - val_accuracy: 0.5297\n","Epoch 49/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9813 - accuracy: 0.5909\n","Epoch 00049: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 89ms/step - loss: 0.9813 - accuracy: 0.5909 - val_loss: 1.0423 - val_accuracy: 0.5297\n","Epoch 50/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9821 - accuracy: 0.5909\n","Epoch 00050: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9820 - accuracy: 0.5909 - val_loss: 1.0435 - val_accuracy: 0.5297\n","Epoch 51/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9816 - accuracy: 0.5909\n","Epoch 00051: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9815 - accuracy: 0.5909 - val_loss: 1.0428 - val_accuracy: 0.5297\n","Epoch 52/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9816 - accuracy: 0.5909\n","Epoch 00052: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9816 - accuracy: 0.5909 - val_loss: 1.0430 - val_accuracy: 0.5297\n","Epoch 53/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9810 - accuracy: 0.5909\n","Epoch 00053: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 54s 90ms/step - loss: 0.9809 - accuracy: 0.5909 - val_loss: 1.0435 - val_accuracy: 0.5297\n","Epoch 00053: early stopping\n","Train: 0.530, Test: 0.530\n"]}],"source":["def Alzheimer_Data_Augmentation_L2_Dropout_Earlystopping(input_shape=(128, 128, 1)):\n","    regularizer = tf.keras.regularizers.l2(0.001)\n","    model = Sequential()\n","    model.add(Input(shape=input_shape))\n","    model.add(Conv2D(128, (5, 5), padding='same', strides=(1, 1), name='conv1', activation='sigmoid', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((9, 9), strides=(3, 3)))\n","    model.add(Conv2D(64, (5, 5), padding='same', strides=(1, 1), name='conv2', activation='sigmoid', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((7, 7), strides=(3, 3)))\n","    model.add(Conv2D(32, (3, 3), padding='same', strides=(1, 1), name='conv3', activation='sigmoid', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((5, 5), strides=(2, 2)))\n","    model.add(Conv2D(32, (3, 3), padding='same', strides=(1, 1), name='conv4', activation='sigmoid', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((3, 3), strides=(2, 2)))    \n","    \n","    model.add(Flatten())\n","    model.add(Dropout(0.5))\n","    model.add(Dense(64, activation='sigmoid'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(4, activation='softmax'))\n","    optimizer = Adam(3.15e-5)\n","    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","model= Alzheimer_Data_Augmentation_L2_Dropout_Earlystopping(input_shape=(128, 128, 1))\n","\n","\n","  #Setting up Early Stopping\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n","mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n","\n","hist_ = model.fit(aug_traning_images, aug_traning_labels, batch_size=128, epochs=200, validation_data=(aug_testing_images, aug_testing_labels), callbacks=[es, mc])\n","saved_model = load_model('best_model.h5')\n","# evaluate the model\n","_, train_acc = saved_model.evaluate(aug_testing_images, aug_testing_labels, verbose=0)\n","_, test_acc = saved_model.evaluate(aug_testing_images, aug_testing_labels, verbose=0)\n","print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HL-omRb4Ap6G","colab":{"base_uri":"https://localhost:8080/","height":455},"executionInfo":{"status":"error","timestamp":1644215291299,"user_tz":300,"elapsed":14481,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"}},"outputId":"360cac8d-c20a-4acb-ece9-aab55f642c9f"},"outputs":[{"output_type":"error","ename":"InternalError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-7fa30912dcf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mhist_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_traning_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug_traning_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_testing_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug_testing_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."]}],"source":["def Alzheimer_Data_Augmentation_L2_Dropout_Earlystopping(input_shape=(128, 128, 1)):\n","    regularizer = tf.keras.regularizers.l2(0.001)\n","    model = Sequential()\n","    model.add(Input(shape=input_shape))\n","    model.add(Conv2D(128, (5, 5), padding='same', strides=(1, 1), name='conv1', activation='tanh', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((9, 9), strides=(3, 3)))\n","    model.add(Conv2D(64, (5, 5), padding='same', strides=(1, 1), name='conv2', activation='tanh', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((7, 7), strides=(3, 3)))\n","    model.add(Conv2D(32, (3, 3), padding='same', strides=(1, 1), name='conv3', activation='tanh', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((5, 5), strides=(2, 2)))\n","    model.add(Conv2D(32, (3, 3), padding='same', strides=(1, 1), name='conv4', activation='tanh', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((3, 3), strides=(2, 2)))    \n","    \n","    model.add(Flatten())\n","    model.add(Dropout(0.5))\n","    model.add(Dense(64, activation='tanh'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(4, activation='softmax'))\n","    optimizer = Adam(3.15e-5)\n","    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","model= Alzheimer_Data_Augmentation_L2_Dropout_Earlystopping(input_shape=(128, 128, 1))\n","\n","\n","  #Setting up Early Stopping\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n","mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n","\n","hist_ = model.fit(aug_traning_images, aug_traning_labels, batch_size=128, epochs=200, validation_data=(aug_testing_images, aug_testing_labels), callbacks=[es, mc])\n","saved_model = load_model('best_model.h5')\n","# evaluate the model\n","_, train_acc = saved_model.evaluate(aug_testing_images, aug_testing_labels, verbose=0)\n","_, test_acc = saved_model.evaluate(aug_testing_images, aug_testing_labels, verbose=0)\n","print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RirflHIEA4sT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644208087855,"user_tz":300,"elapsed":1338895,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"}},"outputId":"ec803490-b27d-4854-c76f-d379b311c2a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","603/603 [==============================] - ETA: 0s - loss: 1.3457 - accuracy: 0.4639\n","Epoch 00001: val_accuracy improved from -inf to 0.52968, saving model to best_model.h5\n","603/603 [==============================] - 68s 97ms/step - loss: 1.3457 - accuracy: 0.4639 - val_loss: 1.1877 - val_accuracy: 0.5297\n","Epoch 2/200\n","603/603 [==============================] - ETA: 0s - loss: 1.1427 - accuracy: 0.5696\n","Epoch 00002: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 57s 94ms/step - loss: 1.1427 - accuracy: 0.5696 - val_loss: 1.1110 - val_accuracy: 0.5297\n","Epoch 3/200\n","603/603 [==============================] - ETA: 0s - loss: 1.0477 - accuracy: 0.5932\n","Epoch 00003: val_accuracy improved from 0.52968 to 0.55643, saving model to best_model.h5\n","603/603 [==============================] - 57s 94ms/step - loss: 1.0477 - accuracy: 0.5932 - val_loss: 1.0412 - val_accuracy: 0.5564\n","Epoch 4/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9865 - accuracy: 0.6119\n","Epoch 00004: val_accuracy did not improve from 0.55643\n","603/603 [==============================] - 57s 94ms/step - loss: 0.9865 - accuracy: 0.6119 - val_loss: 1.1412 - val_accuracy: 0.5559\n","Epoch 5/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.9541 - accuracy: 0.6255\n","Epoch 00005: val_accuracy improved from 0.55643 to 0.57531, saving model to best_model.h5\n","603/603 [==============================] - 57s 94ms/step - loss: 0.9541 - accuracy: 0.6255 - val_loss: 1.1062 - val_accuracy: 0.5753\n","Epoch 6/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9313 - accuracy: 0.6335\n","Epoch 00006: val_accuracy improved from 0.57531 to 0.57648, saving model to best_model.h5\n","603/603 [==============================] - 57s 94ms/step - loss: 0.9313 - accuracy: 0.6335 - val_loss: 1.1523 - val_accuracy: 0.5765\n","Epoch 7/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9141 - accuracy: 0.6408\n","Epoch 00007: val_accuracy improved from 0.57648 to 0.58594, saving model to best_model.h5\n","603/603 [==============================] - 57s 94ms/step - loss: 0.9141 - accuracy: 0.6408 - val_loss: 1.1276 - val_accuracy: 0.5859\n","Epoch 8/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9032 - accuracy: 0.6455\n","Epoch 00008: val_accuracy did not improve from 0.58594\n","603/603 [==============================] - 57s 94ms/step - loss: 0.9032 - accuracy: 0.6455 - val_loss: 1.1736 - val_accuracy: 0.5755\n","Epoch 9/200\n","603/603 [==============================] - ETA: 0s - loss: 0.8885 - accuracy: 0.6509\n","Epoch 00009: val_accuracy improved from 0.58594 to 0.59682, saving model to best_model.h5\n","603/603 [==============================] - 57s 94ms/step - loss: 0.8885 - accuracy: 0.6509 - val_loss: 1.1218 - val_accuracy: 0.5968\n","Epoch 10/200\n","603/603 [==============================] - ETA: 0s - loss: 0.8770 - accuracy: 0.6555\n","Epoch 00010: val_accuracy did not improve from 0.59682\n","603/603 [==============================] - 57s 94ms/step - loss: 0.8770 - accuracy: 0.6555 - val_loss: 1.1318 - val_accuracy: 0.5896\n","Epoch 11/200\n","603/603 [==============================] - ETA: 0s - loss: 0.8666 - accuracy: 0.6608\n","Epoch 00011: val_accuracy did not improve from 0.59682\n","603/603 [==============================] - 57s 94ms/step - loss: 0.8666 - accuracy: 0.6608 - val_loss: 1.1887 - val_accuracy: 0.5930\n","Epoch 12/200\n","603/603 [==============================] - ETA: 0s - loss: 0.8554 - accuracy: 0.6647\n","Epoch 00012: val_accuracy improved from 0.59682 to 0.59779, saving model to best_model.h5\n","603/603 [==============================] - 57s 94ms/step - loss: 0.8554 - accuracy: 0.6647 - val_loss: 1.1744 - val_accuracy: 0.5978\n","Epoch 13/200\n","603/603 [==============================] - ETA: 0s - loss: 0.8458 - accuracy: 0.6714\n","Epoch 00013: val_accuracy did not improve from 0.59779\n","603/603 [==============================] - 57s 94ms/step - loss: 0.8458 - accuracy: 0.6714 - val_loss: 1.0986 - val_accuracy: 0.5946\n","Epoch 14/200\n","602/603 [============================>.] - ETA: 0s - loss: 0.8340 - accuracy: 0.6774\n","Epoch 00014: val_accuracy improved from 0.59779 to 0.60550, saving model to best_model.h5\n","603/603 [==============================] - 57s 94ms/step - loss: 0.8340 - accuracy: 0.6775 - val_loss: 1.1832 - val_accuracy: 0.6055\n","Epoch 15/200\n","603/603 [==============================] - ETA: 0s - loss: 0.8233 - accuracy: 0.6857\n","Epoch 00015: val_accuracy did not improve from 0.60550\n","603/603 [==============================] - 57s 94ms/step - loss: 0.8233 - accuracy: 0.6857 - val_loss: 1.1873 - val_accuracy: 0.6040\n","Epoch 16/200\n","603/603 [==============================] - ETA: 0s - loss: 0.8076 - accuracy: 0.6976\n","Epoch 00016: val_accuracy did not improve from 0.60550\n","603/603 [==============================] - 57s 94ms/step - loss: 0.8076 - accuracy: 0.6976 - val_loss: 1.1698 - val_accuracy: 0.6002\n","Epoch 17/200\n","603/603 [==============================] - ETA: 0s - loss: 0.7899 - accuracy: 0.7119\n","Epoch 00017: val_accuracy improved from 0.60550 to 0.61157, saving model to best_model.h5\n","603/603 [==============================] - 57s 94ms/step - loss: 0.7899 - accuracy: 0.7119 - val_loss: 1.1181 - val_accuracy: 0.6116\n","Epoch 18/200\n","603/603 [==============================] - ETA: 0s - loss: 0.7720 - accuracy: 0.7243\n","Epoch 00018: val_accuracy did not improve from 0.61157\n","603/603 [==============================] - 57s 94ms/step - loss: 0.7720 - accuracy: 0.7243 - val_loss: 1.1277 - val_accuracy: 0.6068\n","Epoch 19/200\n","603/603 [==============================] - ETA: 0s - loss: 0.7517 - accuracy: 0.7372\n","Epoch 00019: val_accuracy did not improve from 0.61157\n","603/603 [==============================] - 56s 94ms/step - loss: 0.7517 - accuracy: 0.7372 - val_loss: 1.1425 - val_accuracy: 0.5974\n","Epoch 20/200\n","603/603 [==============================] - ETA: 0s - loss: 0.7351 - accuracy: 0.7467\n","Epoch 00020: val_accuracy improved from 0.61157 to 0.61181, saving model to best_model.h5\n","603/603 [==============================] - 57s 94ms/step - loss: 0.7351 - accuracy: 0.7467 - val_loss: 1.1458 - val_accuracy: 0.6118\n","Epoch 21/200\n","603/603 [==============================] - ETA: 0s - loss: 0.7132 - accuracy: 0.7587\n","Epoch 00021: val_accuracy improved from 0.61181 to 0.62507, saving model to best_model.h5\n","603/603 [==============================] - 57s 94ms/step - loss: 0.7132 - accuracy: 0.7587 - val_loss: 1.1578 - val_accuracy: 0.6251\n","Epoch 22/200\n","603/603 [==============================] - ETA: 0s - loss: 0.6980 - accuracy: 0.7632\n","Epoch 00022: val_accuracy did not improve from 0.62507\n","603/603 [==============================] - 57s 94ms/step - loss: 0.6980 - accuracy: 0.7632 - val_loss: 1.1916 - val_accuracy: 0.6221\n","Epoch 23/200\n","603/603 [==============================] - ETA: 0s - loss: 0.6773 - accuracy: 0.7714\n","Epoch 00023: val_accuracy did not improve from 0.62507\n","603/603 [==============================] - 57s 94ms/step - loss: 0.6773 - accuracy: 0.7714 - val_loss: 1.1439 - val_accuracy: 0.6218\n","Epoch 00023: early stopping\n","Train: 0.625, Test: 0.625\n"]}],"source":["def Alzheimer_Data_Augmentation_L2_Dropout_Earlystopping(input_shape=(128, 128, 1)):\n","    regularizer = tf.keras.regularizers.l2(0.001)\n","    model = Sequential()\n","    model.add(Input(shape=input_shape))\n","    model.add(Conv2D(128, (5, 5), padding='same', strides=(1, 1), name='conv1', activation='leaky_relu', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((9, 9), strides=(3, 3)))\n","    model.add(Conv2D(64, (5, 5), padding='same', strides=(1, 1), name='conv2', activation='leaky_relu', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((7, 7), strides=(3, 3)))\n","    model.add(Conv2D(32, (3, 3), padding='same', strides=(1, 1), name='conv3', activation='leaky_relu', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((5, 5), strides=(2, 2)))\n","    model.add(Conv2D(32, (3, 3), padding='same', strides=(1, 1), name='conv4', activation='leaky_relu', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((3, 3), strides=(2, 2)))    \n","    \n","    model.add(Flatten())\n","    model.add(Dropout(0.5))\n","    model.add(Dense(64, activation='leaky_relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(4, activation='softmax'))\n","    optimizer = Adam(3.15e-5)\n","    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","model= Alzheimer_Data_Augmentation_L2_Dropout_Earlystopping(input_shape=(128, 128, 1))\n","\n","\n","  #Setting up Early Stopping\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n","mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n","\n","hist_ = model.fit(aug_traning_images, aug_traning_labels, batch_size=128, epochs=200, validation_data=(aug_testing_images, aug_testing_labels), callbacks=[es, mc])\n","saved_model = load_model('best_model.h5')\n","# evaluate the model\n","_, train_acc = saved_model.evaluate(aug_testing_images, aug_testing_labels, verbose=0)\n","_, test_acc = saved_model.evaluate(aug_testing_images, aug_testing_labels, verbose=0)\n","print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q0QoJrMgBFXF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644211323752,"user_tz":300,"elapsed":2482612,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"}},"outputId":"355262ed-79f7-4882-c86b-36601a35fba8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","603/603 [==============================] - ETA: 0s - loss: 1.3032 - accuracy: 0.5208\n","Epoch 00001: val_accuracy improved from -inf to 0.52968, saving model to best_model.h5\n","603/603 [==============================] - 109s 179ms/step - loss: 1.3032 - accuracy: 0.5208 - val_loss: 1.1775 - val_accuracy: 0.5297\n","Epoch 2/200\n","603/603 [==============================] - ETA: 0s - loss: 1.1287 - accuracy: 0.5839\n","Epoch 00002: val_accuracy improved from 0.52968 to 0.53289, saving model to best_model.h5\n","603/603 [==============================] - 107s 177ms/step - loss: 1.1287 - accuracy: 0.5839 - val_loss: 1.0924 - val_accuracy: 0.5329\n","Epoch 3/200\n","603/603 [==============================] - ETA: 0s - loss: 1.0287 - accuracy: 0.6146\n","Epoch 00003: val_accuracy improved from 0.53289 to 0.58619, saving model to best_model.h5\n","603/603 [==============================] - 107s 177ms/step - loss: 1.0287 - accuracy: 0.6146 - val_loss: 1.0418 - val_accuracy: 0.5862\n","Epoch 4/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9772 - accuracy: 0.6291\n","Epoch 00004: val_accuracy did not improve from 0.58619\n","603/603 [==============================] - 106s 177ms/step - loss: 0.9772 - accuracy: 0.6291 - val_loss: 1.0573 - val_accuracy: 0.5853\n","Epoch 5/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9436 - accuracy: 0.6366\n","Epoch 00005: val_accuracy improved from 0.58619 to 0.58890, saving model to best_model.h5\n","603/603 [==============================] - 107s 177ms/step - loss: 0.9436 - accuracy: 0.6366 - val_loss: 1.0670 - val_accuracy: 0.5889\n","Epoch 6/200\n","603/603 [==============================] - ETA: 0s - loss: 0.9160 - accuracy: 0.6445\n","Epoch 00006: val_accuracy improved from 0.58890 to 0.59347, saving model to best_model.h5\n","603/603 [==============================] - 107s 177ms/step - loss: 0.9160 - accuracy: 0.6445 - val_loss: 1.0929 - val_accuracy: 0.5935\n","Epoch 7/200\n","603/603 [==============================] - ETA: 0s - loss: 0.8928 - accuracy: 0.6535\n","Epoch 00007: val_accuracy did not improve from 0.59347\n","603/603 [==============================] - 107s 177ms/step - loss: 0.8928 - accuracy: 0.6535 - val_loss: 1.0918 - val_accuracy: 0.5924\n","Epoch 8/200\n","603/603 [==============================] - ETA: 0s - loss: 0.8693 - accuracy: 0.6666\n","Epoch 00008: val_accuracy improved from 0.59347 to 0.59492, saving model to best_model.h5\n","603/603 [==============================] - 107s 177ms/step - loss: 0.8693 - accuracy: 0.6666 - val_loss: 1.0948 - val_accuracy: 0.5949\n","Epoch 9/200\n","603/603 [==============================] - ETA: 0s - loss: 0.8454 - accuracy: 0.6802\n","Epoch 00009: val_accuracy improved from 0.59492 to 0.61448, saving model to best_model.h5\n","603/603 [==============================] - 107s 177ms/step - loss: 0.8454 - accuracy: 0.6802 - val_loss: 1.0503 - val_accuracy: 0.6145\n","Epoch 10/200\n","603/603 [==============================] - ETA: 0s - loss: 0.8202 - accuracy: 0.6954\n","Epoch 00010: val_accuracy did not improve from 0.61448\n","603/603 [==============================] - 106s 176ms/step - loss: 0.8202 - accuracy: 0.6954 - val_loss: 1.0466 - val_accuracy: 0.6095\n","Epoch 11/200\n","603/603 [==============================] - ETA: 0s - loss: 0.7913 - accuracy: 0.7152\n","Epoch 00011: val_accuracy did not improve from 0.61448\n","603/603 [==============================] - 106s 176ms/step - loss: 0.7913 - accuracy: 0.7152 - val_loss: 1.1125 - val_accuracy: 0.5795\n","Epoch 12/200\n","603/603 [==============================] - ETA: 0s - loss: 0.7618 - accuracy: 0.7345\n","Epoch 00012: val_accuracy improved from 0.61448 to 0.61822, saving model to best_model.h5\n","603/603 [==============================] - 107s 177ms/step - loss: 0.7618 - accuracy: 0.7345 - val_loss: 1.0686 - val_accuracy: 0.6182\n","Epoch 13/200\n","603/603 [==============================] - ETA: 0s - loss: 0.7320 - accuracy: 0.7507\n","Epoch 00013: val_accuracy did not improve from 0.61822\n","603/603 [==============================] - 106s 176ms/step - loss: 0.7320 - accuracy: 0.7507 - val_loss: 1.1258 - val_accuracy: 0.6000\n","Epoch 14/200\n","603/603 [==============================] - ETA: 0s - loss: 0.7070 - accuracy: 0.7636\n","Epoch 00014: val_accuracy did not improve from 0.61822\n","603/603 [==============================] - 106s 176ms/step - loss: 0.7070 - accuracy: 0.7636 - val_loss: 1.1466 - val_accuracy: 0.6009\n","Epoch 15/200\n","603/603 [==============================] - ETA: 0s - loss: 0.6814 - accuracy: 0.7748\n","Epoch 00015: val_accuracy did not improve from 0.61822\n","603/603 [==============================] - 106s 176ms/step - loss: 0.6814 - accuracy: 0.7748 - val_loss: 1.1520 - val_accuracy: 0.5876\n","Epoch 16/200\n","603/603 [==============================] - ETA: 0s - loss: 0.6626 - accuracy: 0.7810\n","Epoch 00016: val_accuracy did not improve from 0.61822\n","603/603 [==============================] - 106s 176ms/step - loss: 0.6626 - accuracy: 0.7810 - val_loss: 1.1769 - val_accuracy: 0.5931\n","Epoch 17/200\n","603/603 [==============================] - ETA: 0s - loss: 0.6349 - accuracy: 0.7918\n","Epoch 00017: val_accuracy did not improve from 0.61822\n","603/603 [==============================] - 106s 176ms/step - loss: 0.6349 - accuracy: 0.7918 - val_loss: 1.1625 - val_accuracy: 0.5998\n","Epoch 18/200\n","603/603 [==============================] - ETA: 0s - loss: 0.6175 - accuracy: 0.7972\n","Epoch 00018: val_accuracy did not improve from 0.61822\n","603/603 [==============================] - 106s 176ms/step - loss: 0.6175 - accuracy: 0.7972 - val_loss: 1.2121 - val_accuracy: 0.5896\n","Epoch 19/200\n","603/603 [==============================] - ETA: 0s - loss: 0.6013 - accuracy: 0.8025\n","Epoch 00019: val_accuracy did not improve from 0.61822\n","603/603 [==============================] - 106s 176ms/step - loss: 0.6013 - accuracy: 0.8025 - val_loss: 1.3861 - val_accuracy: 0.5835\n","Epoch 20/200\n","603/603 [==============================] - ETA: 0s - loss: 0.5796 - accuracy: 0.8096\n","Epoch 00020: val_accuracy did not improve from 0.61822\n","603/603 [==============================] - 106s 176ms/step - loss: 0.5796 - accuracy: 0.8096 - val_loss: 1.1756 - val_accuracy: 0.6066\n","Epoch 21/200\n","603/603 [==============================] - ETA: 0s - loss: 0.5655 - accuracy: 0.8139\n","Epoch 00021: val_accuracy did not improve from 0.61822\n","603/603 [==============================] - 106s 176ms/step - loss: 0.5655 - accuracy: 0.8139 - val_loss: 1.3534 - val_accuracy: 0.5825\n","Epoch 22/200\n","603/603 [==============================] - ETA: 0s - loss: 0.5461 - accuracy: 0.8203\n","Epoch 00022: val_accuracy did not improve from 0.61822\n","603/603 [==============================] - 106s 176ms/step - loss: 0.5461 - accuracy: 0.8203 - val_loss: 1.2525 - val_accuracy: 0.5996\n","Epoch 23/200\n","603/603 [==============================] - ETA: 0s - loss: 0.5262 - accuracy: 0.8269\n","Epoch 00023: val_accuracy did not improve from 0.61822\n","603/603 [==============================] - 106s 176ms/step - loss: 0.5262 - accuracy: 0.8269 - val_loss: 1.4467 - val_accuracy: 0.5742\n","Epoch 00023: early stopping\n","Train: 0.618, Test: 0.618\n"]}],"source":["\n","def Alzheimer_Data_Augmentation_L2_Dropout_Earlystopping(input_shape=(128, 128, 1)):\n","    regularizer = tf.keras.regularizers.l2(0.001)\n","    model = Sequential()\n","    model.add(Input(shape=input_shape))\n","    model.add(Conv2D(128, (5, 5), padding='same', strides=(1, 1), name='conv1', activation='PReLU', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((9, 9), strides=(3, 3)))\n","    model.add(Conv2D(64, (5, 5), padding='same', strides=(1, 1), name='conv2', activation='PReLU', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((7, 7), strides=(3, 3)))\n","    model.add(Conv2D(32, (3, 3), padding='same', strides=(1, 1), name='conv3', activation='PReLU', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((5, 5), strides=(2, 2)))\n","    model.add(Conv2D(32, (3, 3), padding='same', strides=(1, 1), name='conv4', activation='PReLU', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((3, 3), strides=(2, 2)))    \n","    \n","    model.add(Flatten())\n","    model.add(Dropout(0.5))\n","    model.add(Dense(64, activation='PReLU'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(4, activation='softmax'))\n","    optimizer = Adam(3.15e-5)\n","    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","model= Alzheimer_Data_Augmentation_L2_Dropout_Earlystopping(input_shape=(128, 128, 1))\n","\n","\n","  #Setting up Early Stopping\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n","mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n","\n","hist_ = model.fit(aug_traning_images, aug_traning_labels, batch_size=128, epochs=200, validation_data=(aug_testing_images, aug_testing_labels), callbacks=[es, mc])\n","saved_model = load_model('best_model.h5')\n","# evaluate the model\n","_, train_acc = saved_model.evaluate(aug_testing_images, aug_testing_labels, verbose=0)\n","_, test_acc = saved_model.evaluate(aug_testing_images, aug_testing_labels, verbose=0)\n","print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YyBDvzypBqAg","colab":{"base_uri":"https://localhost:8080/","height":844},"executionInfo":{"status":"error","timestamp":1644215118315,"user_tz":300,"elapsed":426630,"user":{"displayName":"Isaac Bensaid","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00246158109180061039"}},"outputId":"4d3e7ca4-451b-4227-8069-01558a702e10"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","603/603 [==============================] - ETA: 0s - loss: 1.4756 - accuracy: 0.4036\n","Epoch 00001: val_accuracy improved from -inf to 0.52968, saving model to best_model.h5\n","603/603 [==============================] - 81s 134ms/step - loss: 1.4756 - accuracy: 0.4036 - val_loss: 1.4232 - val_accuracy: 0.5297\n","Epoch 2/200\n","603/603 [==============================] - ETA: 0s - loss: 1.3866 - accuracy: 0.5886\n","Epoch 00002: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 78s 129ms/step - loss: 1.3866 - accuracy: 0.5886 - val_loss: 1.3684 - val_accuracy: 0.5297\n","Epoch 3/200\n","603/603 [==============================] - ETA: 0s - loss: 1.3415 - accuracy: 0.5909\n","Epoch 00003: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 78s 129ms/step - loss: 1.3415 - accuracy: 0.5909 - val_loss: 1.3360 - val_accuracy: 0.5297\n","Epoch 4/200\n","603/603 [==============================] - ETA: 0s - loss: 1.3103 - accuracy: 0.5909\n","Epoch 00004: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 78s 129ms/step - loss: 1.3103 - accuracy: 0.5909 - val_loss: 1.3117 - val_accuracy: 0.5297\n","Epoch 5/200\n","603/603 [==============================] - ETA: 0s - loss: 1.2846 - accuracy: 0.5909\n","Epoch 00005: val_accuracy did not improve from 0.52968\n","603/603 [==============================] - 78s 129ms/step - loss: 1.2846 - accuracy: 0.5909 - val_loss: 1.2917 - val_accuracy: 0.5297\n","Epoch 6/200\n","227/603 [==========>...................] - ETA: 43s - loss: 1.2680 - accuracy: 0.5943"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-480d5769f350>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mhist_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_traning_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug_traning_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_testing_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug_testing_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def Alzheimer_Data_Augmentation_L2_Dropout_Earlystopping(input_shape=(128, 128, 1)):\n","    regularizer = tf.keras.regularizers.l2(0.001)\n","    model = Sequential()\n","    model.add(Input(shape=input_shape))\n","    model.add(Conv2D(128, (5, 5), padding='same', strides=(1, 1), name='conv1', activation='softmax', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((9, 9), strides=(3, 3)))\n","    model.add(Conv2D(64, (5, 5), padding='same', strides=(1, 1), name='conv2', activation='softmax', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((7, 7), strides=(3, 3)))\n","    model.add(Conv2D(32, (3, 3), padding='same', strides=(1, 1), name='conv3', activation='softmax', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((5, 5), strides=(2, 2)))\n","    model.add(Conv2D(32, (3, 3), padding='same', strides=(1, 1), name='conv4', activation='softmax', kernel_regularizer=regularizer))\n","    model.add(MaxPool2D((3, 3), strides=(2, 2)))    \n","    \n","    model.add(Flatten())\n","    model.add(Dropout(0.5))\n","    model.add(Dense(64, activation='softmax'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(4, activation='softmax'))\n","    optimizer = Adam(3.15e-5)\n","    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","model= Alzheimer_Data_Augmentation_L2_Dropout_Earlystopping(input_shape=(128, 128, 1))\n","\n","\n","  #Setting up Early Stopping\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n","mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n","\n","hist_ = model.fit(aug_traning_images, aug_traning_labels, batch_size=128, epochs=200, validation_data=(aug_testing_images, aug_testing_labels), callbacks=[es, mc])\n","saved_model = load_model('best_model.h5')\n","# evaluate the model\n","_, train_acc = saved_model.evaluate(aug_testing_images, aug_testing_labels, verbose=0)\n","_, test_acc = saved_model.evaluate(aug_testing_images, aug_testing_labels, verbose=0)\n","print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"alzheimermr_model04.ipynb","provenance":[],"authorship_tag":"ABX9TyNo2Ic9laJVBFXw5JBf13Ul"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}